{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c410d9e-fb88-4920-a821-10e0aa6da230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a54097-cf36-4060-9c45-486e017b1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(\"project-20-files\")\n",
    "dataframes = {}\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(\"project-20-files\", file_name) \n",
    "    df_name = os.path.splitext(file_name)[0]  \n",
    "    dataframes[df_name] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a7cc3-05dc-4d1e-bf44-2b59ac844143",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dataframes = {key: df for key, df in dataframes.items() if \"learn\" in key.lower()}\n",
    "\n",
    "merged_training = None\n",
    "\n",
    "for name, df in learn_dataframes.items():\n",
    "    if merged_training is None:\n",
    "        # Use the first DataFrame as the base\n",
    "        merged_training = df\n",
    "    else:\n",
    "        # Merge with the next DataFrame\n",
    "        merged_training = pd.merge(merged_training, df, on=\"pkey\", how=\"outer\")\n",
    "\n",
    "test_dataframes = {key: df for key, df in dataframes.items() if \"test\" in key.lower()}\n",
    "\n",
    "merged_test = None\n",
    "\n",
    "for name, df in test_dataframes.items():\n",
    "    if merged_test is None:\n",
    "        # Use the first DataFrame as the base\n",
    "        merged_test = df\n",
    "    else:\n",
    "        # Merge with the next DataFrame\n",
    "        merged_test = pd.merge(merged_test, df, on=\"pkey\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65a490b-6fa5-40e9-b60c-bc3090fb9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframes that contain \"city\" in their key\n",
    "city_dataframes = {key: df for key, df in dataframes.items() if \"city\" in key.lower()}\n",
    "\n",
    "# Initialize the merged DataFrame\n",
    "merged_city = None\n",
    "\n",
    "# Loop through the filtered DataFrames and merge them on 'INSEE'\n",
    "for name, df in city_dataframes.items():\n",
    "    if merged_city is None:\n",
    "        # Use the first DataFrame as the base\n",
    "        merged_city = df\n",
    "    else:\n",
    "        # Merge with the next DataFrame on the 'INSEE' column\n",
    "        merged_city = pd.merge(merged_city, df, on=\"INSEE\", how=\"outer\")\n",
    "\n",
    "# Resulting merged DataFrame: merged_city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7acaa2-e5c1-4686-8802-c3a598ce5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = pd.read_csv(\"project-20-files/departments.csv\")\n",
    "reg = pd.read_csv(\"project-20-files/regions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82730ebc-c02c-4c93-814c-31c23a5ba17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data = pd.merge(data,merged_city,on = \"INSEE\", how = \"inner\")\n",
    "    data = pd.merge(data,dep, on=\"dep\")\n",
    "    \n",
    "    \n",
    "    # not yet eligeable for retirement\n",
    "    target_activity_types_y = [\"TACT1-1\", \"TACT1-2\", \"TACT2-2\", \"TACT2-4\", \"TACT2-5\"]\n",
    "\n",
    "    # Define the specific columns for retired individuals\n",
    "    retired_col = [\"Previous_occupation_42\", \"previous_emp_type\", \"previous_dep\", \"retirement_pay\"]\n",
    "\n",
    "    # Apply logic to fill NaN values in 'retirement_age' only if activity_type is in target_activity_types_y\n",
    "    data['retirement_age'] = data.apply(\n",
    "    lambda row: 'not_relevant' if pd.isna(row['retirement_age']) and row['activity_type'] in target_activity_types_y \n",
    "        else row['retirement_age'],\n",
    "        axis=1)\n",
    "\n",
    "    # Select columns ending with '_y'\n",
    "    columns_y = [col for col in data.columns if col.endswith('_y')]\n",
    "\n",
    "    # Combine the lists of columns to include the retired columns as well\n",
    "    all_target_columns = columns_y + retired_col\n",
    "    \n",
    "    # Loop through the combined list of columns (both '_y' and retired columns)\n",
    "    for col in all_target_columns:\n",
    "        # Check if the column exists in data\n",
    "        if col in data.columns:\n",
    "            # Check if the column is numerical\n",
    "            if pd.api.types.is_numeric_dtype(data[col]):\n",
    "                # For numerical columns, set 0 for matching activity types, keep existing values otherwise\n",
    "                data[col] = data.apply(\n",
    "                    lambda row: 0 if row[\"activity_type\"] in target_activity_types_y and pd.isna(row[col]) else row[col],\n",
    "                    axis=1\n",
    "                )\n",
    "            else:\n",
    "                # For non-numerical columns, set 'not_relevant' for matching activity types\n",
    "                data[col] = data.apply(\n",
    "                    lambda row: \"not_relevant\" if row[\"activity_type\"] in target_activity_types_y and pd.isna(row[col]) else row[col],\n",
    "                    axis=1\n",
    "                )\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## There is a special group of 251 observations that are considered retired but that with most likelihood never worked.\n",
    "    ## which very likely is people that has never worked due to some reason (old housewifes, institutionalized for instance)\n",
    "    # this would explain lack of data regarding previous work\n",
    "    \n",
    "    \n",
    "    csp_codes = [\"csp_8_5\", \"csp_8_6\"]\n",
    "    \n",
    "    # Function to apply the changes\n",
    "    def fill_missing_values(row):\n",
    "        # Check if Occupation_42 is one of the csp codes and the columns are NaN\n",
    "        if row[\"Occupation_42\"] in csp_codes:\n",
    "            if pd.isna(row[\"Previous_occupation_42\"]):\n",
    "                row[\"Previous_occupation_42\"] = \"never worked\"\n",
    "            if pd.isna(row[\"previous_emp_type\"]):\n",
    "                row[\"previous_emp_type\"] = \"never worked\"\n",
    "            if pd.isna(row[\"retirement_age\"]):\n",
    "                row[\"retirement_age\"] = \"never worked\"\n",
    "        return row\n",
    "    \n",
    "    # Apply the function to the DataFrame\n",
    "    data = data.apply(fill_missing_values, axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##\n",
    "    ## Not working and will therefore not have any values for working related questions. \n",
    "    target_activity_types = [\"TACT2-1\", \"TACT1-2\",\"TACT2-2\", \"TACT2-4\", \"TACT2-5\"]\n",
    "    \n",
    "    data.loc[data[\"activity_type\"].isin(target_activity_types) & data[\"PAY\"].isna(), \"PAY\"] = 0\n",
    "    data.loc[data[\"activity_type\"].isin(target_activity_types) & data[\"emp_type\"].isna(), \"emp_type\"] = \"not_relevant\"\n",
    "    \n",
    "    # Select columns ending with '_x'\n",
    "    columns_x = [col for col in data.columns if col.endswith('_x')]\n",
    "    \n",
    "    # Loop through the selected columns\n",
    "    for col in columns_x:\n",
    "        # Check if the column is numerical\n",
    "        if pd.api.types.is_numeric_dtype(data[col]):\n",
    "            # For numerical columns, set 0 for matching activity types, keep existing values otherwise\n",
    "            data[col] = data.apply(\n",
    "                lambda row: 0 if row[\"activity_type\"] in target_activity_types and pd.isna(row[col]) else row[col],\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            # For non-numerical columns, set 'not_relevant' for matching activity types\n",
    "            data[col] = data.apply(\n",
    "                lambda row: \"not_relevant\" if row[\"activity_type\"] in target_activity_types and pd.isna(row[col]) else row[col],\n",
    "                axis=1\n",
    "            )\n",
    "   \n",
    "    \n",
    "    ## Sport people are either \n",
    "    data.loc[:, \"SPORTS\"] = data.loc[:, \"SPORTS\"].fillna(\"not_registered\")\n",
    "\n",
    "\n",
    "    ###\n",
    "    data.loc[data['emp_type'].str.startswith('ec-2-1', na=False), 'employer_type_x'] = \"ct_6\"\n",
    "    data.loc[data['emp_type'].str.startswith('ec-2-2', na=False), 'employer_type_x'] = \"ct_9\"\n",
    "    data.loc[data['emp_type'].str.startswith('ec-2-3', na=False), 'employer_type_x'] = \"ct_9\"\n",
    "    \n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2-1', na=False), 'employer_type_y'] = \"ct_6\"\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2-2', na=False), 'employer_type_y'] = \"ct_9\"\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2-3', na=False), 'employer_type_y'] = \"ct_9\"\n",
    "\n",
    "\n",
    "    ###\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2', na=False), 'work_condition_x'] = \"N\"\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2', na=False), 'work_condition_y'] = \"N\"\n",
    "    \n",
    "    ###\n",
    "    data.loc[data['work_desc_x'].str.startswith('231a', na=False), 'employee_count_x'] = \"tr_6\"\n",
    "    data.loc[data['emp_type'].str.startswith('ec-2-1', na=False), 'employee_count_x'] = \"tr_1\"\n",
    "    \n",
    "    data.loc[data['work_desc_y'].str.startswith('231a', na=False), 'employee_count_y'] = \"tr_6\"\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2-1', na=False), 'employee_count_y'] = \"tr_1\"\n",
    "    \n",
    "    ###\n",
    "    data.loc[data['emp_type'].str.startswith('ec-1-6', na=False), 'Type_of_contract_x'] = \"CDI\"\n",
    "    data.loc[data['emp_type'].str.startswith('ec-2', na=False), 'Type_of_contract_x'] = \"No contract\"\n",
    "    \n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-1-6', na=False), 'Type_of_contract_y'] = \"CDI\"\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2', na=False), 'Type_of_contract_y'] = \"No contract\"\n",
    "\n",
    "\n",
    "    ###\n",
    "    data.loc[data['emp_type'].str.startswith('ec-2', na=False), 'JOB_CATEGORY_x'] = \"not employee\"\n",
    "    data.loc[data['emp_type'].str.startswith('ec-1-6', na=False), 'JOB_CATEGORY_x'] = \"O\"\n",
    "    \n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2', na=False), 'JOB_CATEGORY_y'] = \"not employee\"\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-1-6', na=False), 'JOB_CATEGORY_y'] = \"O\"\n",
    "\n",
    "    ###\n",
    "    data.loc[data['emp_type'].str.startswith('ec-2', na=False), 'PAY'] = 0\n",
    "\n",
    "    data.loc[data['previous_emp_type'].str.startswith('ec-2', na=False), 'retirement_pay'] = 0\n",
    "\n",
    "\n",
    "    ###\n",
    "    data['working_but_nocon_income'] = data['emp_type'].apply(\n",
    "        lambda x: 1 if str(x).startswith('ec-2') else 0)\n",
    "        \n",
    "    \n",
    "    #priests\n",
    "    data.loc[\n",
    "        (data['Occupation_42'] == 'csp_4_4') & data['PAY'].isna(), \n",
    "        ['PAY', 'working_but_nocon_income']\n",
    "    ] = [0, 1]\n",
    "    \n",
    "    data.loc[\n",
    "        (data['Occupation_42'] == 'csp_4_4') & data['employer_type_x'].isna(), \"employer_type_x\"] = \"ct_2\" \n",
    "    \n",
    "    #priests retired\n",
    "    data.loc[\n",
    "        (data['Previous_occupation_42'] == 'csp_4_4') & data['PAY'].isna(), \n",
    "        ['PAY', 'working_but_nocon_income']\n",
    "    ] = [0, 1]\n",
    "    \n",
    "    data.loc[\n",
    "        (data['Occupation_42'] == 'csp_4_4') & data['employer_type_x'].isna(), \"employer_type_x\"] = \"ct_2\" \n",
    "    \n",
    "    \n",
    "    data = data.drop([\"JOB_CATEGORY_x\", \"JOB_CATEGORY_y\"], axis=1)\n",
    "    \n",
    "    # Creating a new column 'fixed_contract' based on conditions applied to 'emp_type'\n",
    "    def assign_fixed_contract(emp_type):\n",
    "        if emp_type.startswith('ec-1') and emp_type != 'ec-1-6':\n",
    "            return 'yes'\n",
    "        elif emp_type == 'ec-1-6':\n",
    "            return 'no contract'\n",
    "        else:\n",
    "            return 'no'\n",
    "    \n",
    "    data['fixed_contract'] = data['emp_type'].apply(assign_fixed_contract)\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b33ba50f-a655-4ec3-b0d6-0066e2c22d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_training = preprocessing(merged_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3a221ba-9faf-4a80-8ca9-34117a937c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_training_sampled = merged_training.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6710ba6-aa4c-4547-b904-fde15f8ebf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 88.40%\n",
      "Precision: 83.30%\n",
      "Recall: 79.74%\n",
      "F1 Score: 81.48%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      6806\n",
      "           1       0.83      0.80      0.81      3203\n",
      "\n",
      "    accuracy                           0.88     10009\n",
      "   macro avg       0.87      0.86      0.87     10009\n",
      "weighted avg       0.88      0.88      0.88     10009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Copy the original dataset\n",
    "df = merged_training.copy()\n",
    "label_mapping = {'I': 0, 'N':1}\n",
    "df['target'] = df['target'].map(label_mapping)\n",
    "# Separate the target, features, and pkey\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# Handle categorical features using Label Encoding\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    X[col] = encoder.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Split the dataset into training and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # Stratify based on the target variable\n",
    ")\n",
    "\n",
    "\n",
    "# Instantiate the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
    "\n",
    "# Hyperparameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 30),  # Keep this as is, a larger learning rate often helps explore the parameter space better\n",
    "    'max_depth': [3, 5, 6, 7, 10, 12],  # Increase the depth range slightly to allow for more complex models\n",
    "    'n_estimators': [200, 500, 1000, 1500, 2000],  # Increase n_estimators to allow for more boosting rounds\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],  # No changes, subsample is important for preventing overfitting\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],  # No changes, colsample_bytree is also important for preventing overfitting\n",
    "    'gamma': [0, 0.1, 0.5, 1, 2, 5],  # Increased the range for gamma, which can help regularize and reduce overfitting\n",
    "    'min_child_weight': [1, 3, 5, 7, 10],  # Expanded the range to allow more fine-tuned choices\n",
    "    'scale_pos_weight': [1, 2, 5],  # This is useful if you have class imbalance\n",
    "    'max_delta_step': [0, 1, 5]  # This is useful to stabilize training when there's class imbalance or other issues\n",
    "}\n",
    "\n",
    "# Randomized search over the parameter grid\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model, param_distributions=param_dist,\n",
    "    n_iter=100, cv=3, verbose=1, n_jobs=-1, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from RandomizedSearchCV\n",
    "best_random_model = random_search.best_estimator_\n",
    "\n",
    "y_pred = best_random_model.predict(X_test)  # Predicted labels\n",
    "\n",
    "# Calculate and print metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1 Score: {f1 * 100:.2f}%')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6dee59b1-fe52-4993-81b9-8b3d8fe83734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_predict(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    # Handle categorical features using Label Encoding\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = encoder.fit_transform(df[col].astype(str))\n",
    "    # Predict numeric target using the trained model\n",
    "    df[\"target\"] = best_random_model.predict(df)\n",
    "    \n",
    "    # Define label mapping\n",
    "    label_mapping = {0: 'I', 1: 'N'}\n",
    "    \n",
    "    # Map numeric predictions to categorical labels\n",
    "    df[\"target\"] = df[\"target\"].map(label_mapping)\n",
    "\n",
    "    df = df[[\"pkey\",\"target\"]]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "efc11403-a5b1-4bbb-ab8b-14b46d2f39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "xg_predict(merged_test).to_csv('predictions.csv', index=False, sep=',', decimal='.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
